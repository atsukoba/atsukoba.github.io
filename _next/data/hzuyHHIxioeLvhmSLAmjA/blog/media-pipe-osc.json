{"pageProps":{"content":"\nMediapipe: <https://github.com/google/mediapipe>\n\nMediaPipe Hand: <https://google.github.io/mediapipe/solutions/hands>\n\n## スクリプト\n\n```python\n# Atsuya Kobayashi 2020-12-22\n# Reference: https://google.github.io/mediapipe/solutions/hands\n# LICENCE: MIT\n\nfrom itertools import chain\n\nimport mediapipe as mp\nfrom cv2 import cv2\nfrom pythonosc import udp_client\n\nIP = \"127.0.0.1\"\nPORT = 7474\nVIDEO_DEVICE_ID = 0\nRELATIVE_AXIS_MODE = True\n\nHAND_LANDMARK_NAMES = [\n    \"wrist\",\n    \"thumb_1\",\n    \"thumb_2\",\n    \"thumb_3\",\n    \"thumb_4\",\n    \"index_1\",\n    \"index_2\",\n    \"index_3\",\n    \"index_4\",\n    \"middle_1\",\n    \"middle_2\",\n    \"middle_3\",\n    \"middle_4\",\n    \"ring_1\",\n    \"ring_2\",\n    \"ring_3\",\n    \"ring_4\",\n    \"pinky_1\",\n    \"pinky_2\",\n    \"pinky_3\",\n    \"pinky_4\"\n]\n\n\ndef extract_detected_hands_points(multi_hand_landmarks,\n                                  send_osc_client=None):\n\n    if multi_hand_landmarks is not None:\n        for hand_idx, landmarks in enumerate(multi_hand_landmarks):\n            for point_idx, points in enumerate(landmarks.landmark):\n\n                # if you want to check data on console\n                print(f\"Hand: {hand_idx}, {HAND_LANDMARK_NAMES[point_idx]},\"\n                      + f\"x:{points.x} y:{points.y} z:{points.z}\")\n                \"\"\"\n                if you want to send data to addresses correspoding\n                to landmarks names on detected hands, use berow\n                \"\"\"\n                # if send_osc_client is not None:\n                #     send_osc_client.send_message(f\"/{HAND_LANDMARK_NAMES[point_idx]}\",\n                #                                  [points.x, points.y])\n\n            \"\"\"if you want to send data to single input address, use berow\"\"\"\n            if send_osc_client is not None:\n                send_osc_client.send_message(\n                    f\"/YOUR_OSC_ADDRESS\",\n                    list(chain.from_iterable([[p.x, p.y] for p in landmarks.landmark])))\n\n\nif __name__ == \"__main__\":\n\n    mp_drawing = mp.solutions.drawing_utils\n    mp_hands = mp.solutions.hands\n\n    hands = mp_hands.Hands(\n        min_detection_confidence=0.5, min_tracking_confidence=0.5)\n\n    cap = cv2.VideoCapture(VIDEO_DEVICE_ID)\n\n    osc_client = udp_client.SimpleUDPClient(IP, PORT)\n\n    while cap.isOpened():\n        success, image = cap.read()\n        if not success:\n            print(\"Ignoring empty camera frame.\")\n            # If loading a video, use 'break' instead of 'continue'.\n            continue\n\n        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n        image.flags.writeable = False\n        results = hands.process(image)\n        extract_detected_hands_points(results.multi_hand_landmarks,\n                                      send_osc_client=osc_client)\n        image.flags.writeable = True\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                mp_drawing.draw_landmarks(\n                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n        cv2.imshow('Detected Hands', image)\n\n        if cv2.waitKey(5) & 0xFF == 27:\n            break\n\n    hands.close()\n    cap.release()\n```\n","data":{"title":"MediaPipeによるお手軽手認識とリアルタイムおもちゃのためのOSC連携","description":"","slug":"media-pipe-osc","date":"2020-12-22T00:26:20.000Z","category":"Tech Blog","tags":["MediaPipe","Open Sound Control"],"keyVisual":"https://i.gyazo.com/229d4f1e990ac46f3d4e4b5dfd9806c3.jpg"}},"__N_SSG":true}