{"pageProps":{"data":["---\ndescription: \"\"\ntitle: Hexoでブログ的な物を開設しました。\nslug: blog-start\ndate: 2019-02-13 14:52:43\ncategory: \"Tech Blog\"\ntags: [Hexo, ご報告]\n---\n\natsuyaです。この度ブログ的な物をつくりました。\nTech的なお勉強のこと，文献調査ログ，趣味のことなど，まとめていきたいと思います。\n\n<!-- more -->\n\n### 背景\n\n現状大学三年生なのですが，事情により休学していたため来年度も3年生です。  \n休学中は単純に病気療養と，回復後はエンジニアとしてアルバイトをしていました。  \n「エンジニアはアウトプットが大事だ」（スキルアップと転職市場等での評価のため）みたいな文言をよく目にしたのと，実際自身がTechブログやQiita，はてなブログ等にめちゃめちゃお世話になったのもあり，じゃあ自分でもやってみっかという軽い気持ちで，自動車学校の学科の合間に作りました。\n\n### やったこと\n\n以前`WordPress`を用いたCMS構築などをしたことがあったためWordPress環境を一度作ったのですが，ブラウザでの編集が面倒であったりサーバー借りなきゃいけない，Markdownで記事書きたい（他の多くの方も同様の理由でサイトジェネレータでのブログ運営に変更している）ということでJSでの静的サイトジェネレータ`Hexo`を採用しました。格安ドメインをお名前.comで取得し，GitHub Pagesでホスティングしています。メチャ楽でした。  \n\nテーマは元々Tumblrにあった[`APOLLO`](http://sanographix.github.io/tumblr/apollo/)というテーマのHexo移植版を導入しました。結構いろんな人が使ってます。`.ejs`なので，もともとhtml書きだった私にとってもとっつきやすくて良いです。今後色々改変する予定。\n\nMarkdownの記事の更新をしたら，\n\n```bash\n% hexo d -g\n```\n\nこれでデプロイ完了。とにかく楽。\n\n\n様々参考とさせていただいた（パクった）エントリ等を掲載します。ありがとうございました。\n\n- [Hexo docs](https://hexo.io/docs/setup)\n- [Hexoでローカルに静的なブログを作ってみて基本構成を把握する](https://tech.qookie.jp/posts/info-hexo-local/)\n- [Hexoを使って個人ブログ作成, Github Pagesにデプロイするまで (Qiita)](https://qiita.com/wawawa/items/1a2f174fb29c35302543)\n- [Hexo設定ファイル](http://hatobane.github.io/hexo/Hexo-config/)\n- [GitHub Pages へデプロイするには？](https://ja.nuxtjs.org/faq/github-pages/)\n- [masato's blog](http://masato.github.io/)\n","---\nslug: choichanglim-demo\ntitle: ChoiChanglimの楽曲デモを公開\ndate: 2020-01-28 03:28:29\ncategory: Music\ntags: [ChoiChanglim]\n---\n\n私がドラムを担当しているバンドChoi Changlimで仮レコーディング(一発撮り)した楽曲デモを公開しました。\n\n<iframe width=\"100%\" height=\"150\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/750357343&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true\"></iframe>\n\n<iframe width=\"100%\" height=\"150\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/750351748&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true\"></iframe>","---\nslug: doc2vec-sansan-blog\ntitle: 「Doc2Vecによる文書ベクトル推論の安定化について」を書きました。\ndate: 2019-04-11 01:08:35\ncategory: \"Tech Blog\"\ntags: [Python, NLP]\n---\n\n先日までインターンでお世話になっていたSansan株式会社のDSOCという部署で，テックブログを書きましたのでここでも共有しておきます。細かい詳細や追記，追試などもここに今後書くかもしれないです。-> [Doc2Vecによる文書ベクトル推論の安定化について - Sansan Builders Box](https://buildersbox.corp-sansan.com/entry/2019/04/10/110000)","---\ndescription: \"\"\ntitle: Doc2VecとOptunaを使ったSVMでのテキスト分類を作ってみた\nslug: doc2vec-svm-sentenceclassification\ndate: 2019-02-15 23:20:16\ncategory: \"Tech Blog\"\ntags: [ML, NLP]\n---\n\nOptunaを使ってみる練習として，Doc2Vecを用いてテキスト分類をするやつをサクっと書きました。  \n出力はモデルのaccuracy，F1と，`pyplot`でのConfusion Matrixを出力します。\n\n<!-- more -->\n\nラベルデータを下記の形で用意します\n\n| DOCUMENT_FILE_NAME(id) | LABEL(labels) |\n|:----------------------:|:-------------:|\n|        foo.txt         |      bar      |\n|        bar.txt         |      foo      |\n\n使い方は，`% python document_SVClassifier.py -h`で。\n\n各テキストデータ毎に分類を行います。\n\n### Source ([github](https://gist.github.com/atsukoba/b33967dee47e92f58240a3a544d0650b))\n\n\n```python\n# Author: Atsuya Kobayashi @atsuya_kobayashi\n# 2019/02/15 17:20\n\n\"\"\"Support Vector Document Classifier with doc2vec & Optuna\n- .csv label file must be in the form of following style\n|DOCUMENT_FILE_NAME(id)|LABEL(labels)|\n|----------------------|-------------|\n|       foo.txt        |     bar     |\n|       bar.txt        |     foo     |\n\"\"\"\n\nimport argparse\nimport itertools\nimport optuna\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVC\nfrom gensim.models import Doc2Vec\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n\n# parameters\nPATH_TO_CSVFILE = \"\"\nTEXTFILE_TARGET_DIR = \"/\"\nPATH_TO_PRETRAINED_DOC2VEC_MODEL = \"\"\nN_OPTIMIZE_TRIAL = 20\nUSE_MORPH_TOKENIZER = False\n\ndef plot_confusion_matrix(cm, classes, normalize=False,\n                          title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    return\n\n\n# for Optuna\ndef obj(trial):\n    # C\n    svc_c = trial.suggest_loguniform('C', 1e0, 1e2)\n    # kernel\n    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n    # SVC\n    clf = SVC(C=svc_c, kernel=kernel)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    # 3-fold cross validation\n    score = cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3)\n    accuracy = score.mean()\n    return 1.0 - accuracy\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description='Train a Support Vector Sentence Classifier')\n    parser.add_argument('csv', help='PATH TO CSVFILE')\n    parser.add_argument('dir', help='TEXTFILE TARGET DIRECTORY')\n    parser.add_argument('model', help='PATH TO PRETRAINED DOC2VEC MODEL FILE')\n    parser.add_argument(\"-N\", \"--n_trial\", dest='n', default=20, type=int,\n                        help='N OF OPTIMIZE TRIALS (Default is 20times)')\n    parser.add_argument(\"-M\", \"--mecab\", dest='mecab', action='store_true',\n                        help='USE MECAB Owakati TAGGER')\n    args = parser.parse_args()\n    PATH_TO_CSVFILE = args.csv\n    TEXTFILE_TARGET_DIR = args.dir\n    PATH_TO_PRETRAINED_DOC2VEC_MODEL = args.model\n    N_OPTIMIZE_TRIAL = args.n\n    USE_MORPH_TOKENIZER = args.mecab\n\n    m = MeCab.Tagger(\"-Owakati\")\n    df = pd.read_csv(PATH_TO_CSVFILE)\n\n    documents = []\n    for fname in tqdm(df.id, desc=\"Reading Files\"):\n        with open(TEXTFILE_TARGET_DIR + fname) as f:\n            if USE_MORPH_TOKENIZER:\n                doc = m.parse(f.read()).strip().split()\n            else:\n                doc = f.read().strip().split()\n        documents.append(doc)\n\n    model = Doc2Vec.load(PATH_TO_PRETRAINED_DOC2VEC_MODEL)\n    document_vectors = [model.infer_vector(s) for s in tqdm(documents)]\n\n    X_train, X_test, y_train, y_test = train_test_split(document_vectors, df.labels,\n                                                        test_size=0.5, random_state=42)\n\n    study = optuna.create_study()\n    study.optimize(obj, n_trials=N_OPTIMIZE_TRIAL)\n    # fits a model with best params\n    clf = SVC(C=study.best_params[\"C\"], kernel=study.best_params[\"kernel\"])\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    # Compute confusion matrix\n    cnf_matrix = confusion_matrix(y_test, y_pred)\n    np.set_printoptions(precision=2)\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=data.categories,\n                          title='Confusion matrix, without normalization')\n    plt.show()\n    # print result\n    print(f\"Acc = {accuracy_score(y_test, y_pred)}\")\n    print(f\"F1 = {f1_score(y_test, y_pred, average='weighted')}\")\n```\n","---\ndescription: \"\"\ntitle: DockerでRstanが使えるJupyterLabのサーバーを建てる\nslug: docker-r-jupyterlab\ndate: 2019-07-22 11:23:52\ncategory: \"Tech Blog\"\ntags: [Docker, R, Jupyter Lab]\n---\n\nRstanの環境構築でコケるので。\n\n<!-- more -->\n\n## Dockerfile\n\n```Dockerfile\nFROM jupyter/datascience-notebook\n\nRUN pip install jupyterlab\nRUN jupyter serverextension enable --py jupyterlab\nRUN jupyter labextension install @jupyterlab/git\nRUN pip install jupyterlab-git\nRUN jupyter serverextension enable --py jupyterlab_git\n\nFROM rocker/tidyverse\n\n# Change environment to Japanese(Character and DateTime)\nENV LANG ja_JP.UTF-8\nENV LC_ALL ja_JP.UTF-8\nRUN sed -i '$d' /etc/locale.gen \\\n  && echo \"ja_JP.UTF-8 UTF-8\" >> /etc/locale.gen \\\n  && locale-gen ja_JP.UTF-8 \\\n  && /usr/sbin/update-locale LANG=ja_JP.UTF-8 LANGUAGE=\"ja_JP:ja\"\nRUN /bin/bash -c \"source /etc/default/locale\"\nRUN ln -sf  /usr/share/zoneinfo/Asia/Tokyo /etc/localtime\n\n# Install Japanese fonts\nRUN apt-get update && apt-get install -y \\\n  fonts-ipaexfont\n\n# Install packages\nRUN Rscript -e \"install.packages(c('githubinstall','rstan','ggmcmc','bayesplot','brms'))\"\n\nRUN jupyter lab --no-browser --port=8888\n\n```\n\n## References\n\n- [dockerhub:kazutan/stan-d](https://hub.docker.com/r/kazutan/stan-d/)\n- [dockerhub:jupyter/datascience-notebook](https://hub.docker.com/r/jupyter/datascience-notebook/)\n- [Qiita:DockerでJupyterLabを構築する](https://qiita.com/muk-ai/items/a147cfd2cafc57420b15)\n- [Qiita:Dockerを利用してRStudio ServerでRStan環境を準備する](https://qiita.com/kazutan/items/f1447cbabed8d4dd50b8)\n","---\ndescription: \"\"\ntitle: herokuでPython製LINEbot+WebAppをCIする\nslug: flask-line-bot-heroku\ndate: 2019-07-26 03:14:45\ncategory: \"Tech Blog\"\ntags: [Python, flask, LINE Bot]\n---\n\nLINE Messaging API + line-bot-sdk によるPythonでのチャットボット作成と，同等機能をもつWebアプリケーションを同時に作成し，herokuへデプロイ，継続的インテグレーションでmasterへのpushで自動デプロイさせました。\n\n<!-- more  -->\n\nコードの詳細等はそもそも[ゴー☆ジャスをつくる](https://qiita.com/jg43yr/items/30defcdb69163612fc27)をLINE BotとWebアプリ化したリポジトリがあるので，そちらを参照すること。\n\n<blockquote class=\"embedly-card\"><h4><a href=\"https://github.com/atsukoba/GorgeousApp\">atsukoba/GorgeousApp</a></h4><p>キミのハートに、レボ☆リューション！. Contribute to atsukoba/GorgeousApp development by creating an account on GitHub.</p></blockquote>\n<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script>\n\n[Webアプリ](https://gorgeous-app.herokuapp.com/)\n\n## herokuの下準備\n\nまず，テキスト処理系のモノをherokuにデプロイするならば`MeCab`+`mecab-python`等の形態素解析器を入れたい。ので，buildpackを複数入れられる`heroku-buildpack-multi`を選択し，pythonとlinuxbrewのbuildpackを入れることでMeCab等の`brew install`を可能にする\n\nまずheroku cli。\n\n```shell\nbrew tap heroku/brew && brew install heroku\nheroku create --buildpack https://github.com/heroku/heroku-buildpack-multi\n```\n\n`.buildpack`へは以下を\n\n```.buildpack\nhttps://github.com/heroku/heroku-buildpack-python.git\nhttps://github.com/sunny4381/heroku-buildpack-linuxbrew.git\n```\n\nlinuxbrew用の`.celler`に\n\n```.celler\nmecab\nmecab-ipadic\n```\n\nと書いておき，`requirements.txt`も適切にかけば環境が整う。\n\n以下を参照すると良い。(sklearnを動かすためにbuildpack-multiでcondaを入れている)\n\n[herokuでpython+django+scikit-learn+mecab(1)](https://qiita.com/kenchin110100/items/6f1c84ac8858525fffc5)\n\n## LINE Developers / Messaging API の設定\n\n![screenshot](https://i.gyazo.com/bfb34348c18382476989e734c3106351.png)\n\n各種アクセストークン等取得しておく。\n以下が多分文字通りわかりやすい。\n\n[LINE BOTの作り方を世界一わかりやすく解説（１）【アカウント準備編】](https://qiita.com/yoshizaki_kkgk/items/bd4277d3943200beab26)\n\n## flaskでAPIを書く\n\nLINE bot用のテンプレート ([app.py](https://github.com/line/line-bot-sdk-python/blob/master/examples/flask-kitchensink/app.py)) があり，それを使う。そこでは`/callback`への`POST`に対して返答を行うので，それに加えて，最低限ルートへの`GET`, `POST`の処理を書いておく。(`flask.render_template()`でテンプレートHTMLを返すようにしておく)  \n\nここで，テキスト処理用のモジュールを読んでおいて，`POST`で入力されたテキストに対しての返答を`JSON`で受け取り，`jinja2`で扱えるように`render_template`に渡してあげる。\n\n`linebot.LineBotAPI`と`linebot.WebhookHandler`のインスタンス化に必要な`CHANNEL_ACCESS_TOKEN`と`CHANNEL_SECRET`は環境変数に入れておき，`os.environ.get`で取得する。heroku上では管理画面から登録し，ローカルでのテストではテキトーに何か入れておく。\n\n`app.run(debug=True)`でAPIのテストをする。\n\n## Jinja2を書く\n\nテキスト処理なので，最低限入力ボックスと出力結果のUIはほしい。ので，HTMLとCSSを書く。`flask`のappと同階層に`template/`を作成し，そこにhtmlを書いていく。\n\n普通に\n\n```html\n<form action=\"/\" method=\"POST\">\n    <input type=\"text\" name=\"input\"/>\n</form>\n```\n\nのように記入すれば`POST`できるし，`Jinja`内では，2重ブラケット内で\n\n```html\n<div id=\"data\">\n    {{ data[\"key] }}\n</div>\n```\n\n`render_template()`内に渡されたキーワード変数がそのまま辞書としてアクセスできる。\n\nただ，二重ブラケット内で素のPythonが書けるわけではない(とくにループやデータのキャストとか)ので，以下等を参照すると良い。\n\n[pythonのためのテンプレートエンジン「Jinja2」便利な機能](https://qiita.com/kotamatsuoka/items/a95faf6655c0e775ee22)\n\n`templates/`と同階層に`static/`を作成しておけば，そこにcssやjsを書いてフロントをすこしいじれる。私はここで`sass/`内にsassを書き，`css/style.css`へコンパイルすることで，\n\n```html\n<link rel=\"stylesheet\" href=\"/static/css/style.css\">\n```\n\nのようにいつもどおりheadから読んで使っている。\n\n## herokuとGitHubの連携\n\nherokuで動かすために，`Procfile`を書く。  \nwsgiとして`gunicorn`を用いるのが楽で，ポピュラーというかflaskだと必須か。\nprocess typeは`web`に設定し，gunicornを起動する。\n\n`web: gunicorn app.app:app --log-file=-`\n\nアプリケーションのインスタンス`flask.Flask`を指定してあげる。  \n`アプリケーションモジュール:アプリケーションインスタンス/関数`という指定方法。\n\n[Gunicorn - Python WSGI HTTP Server for UNIX](https://gunicorn.org/)\n\n![ss](https://i.gyazo.com/75a46844773d4bddcae040fac45bff17.png)\n\nその後はGitHub上にリモートレポジトリを作成し，herokuのダッシュボード上で認証・連携をする。この時にGUIで`config vars`からLINEから発行されたアクセストークン等を登録できる。\n\nあとは，普通にgit pushすれば，デプロイが走る。  \nデプロイ中のログに加えPythonから`logging`や`print`で出力した内容もダッシュボードのログから確認できるため，そこで逐一チェックすればまあ動くものは作れるはず。\n","---\ndescription: \"\"\ntitle: JupyterLabのExtensionメモ\nslug: jlab-ext\ndate: 2019-04-19 05:07:47\ncategory: \"Tech Blog\"\ntags: [Python, Jupyter Lab]\n---\n\nJupyter Labの拡張機能メモ\n\n<!-- more -->\n\n## Git\n\n```bash\njupyter labextension install @jupyterlab/git\npip install -e git+https://github.com/SwissDataScienceCenter/jupyterlab-git.git@fix-git-current-dir#egg=jupyterlab_git\njupyter serverextension enable --py jupyterlab_git\n```\n\n## Var Inspector\n\n```bash\njupyter labextension install @lckr/jupyterlab_variableinspector\n```\n\n## ToC\n\n```bash\njupyter labextension install @jupyterlab/toc\npip install jupyterlab_code_formatter\njupyter labextension install @ryantam626/jupyterlab_code_formatter\njupyter serverextension enable --py jupyterlab_code_formatter\n```\n\n## autoPEP8\n\n```bash\npip install autopep8\n\n```\n","---\ndescription: \"\"\ntitle: 任天堂SwitchのジョイコンをPython経由で楽器にする\nslug: joycon-driver\ndate: 2020-01-26 03:40:48\ncategory: \"Tech Blog\"\ntags: [Python, Max/MSP, Joycon]\n---\n\nBluetooth接続したJoy-Conからhid経由で情報取得するPythonライブラリ`joycon-python`の開発に参加し，その`joycon-python`を用いて信号をOSC (Open Sound Control)に飛ばすスクリプト`joycon-osc`を作成し，その`joycon-osc`を用いて送信した情報をMaxで受け取って音にしました。\n\n<!-- more -->\n\nこんなものです。\n\n<div style=\"margin:0 auto;width:fit-content;\">\n<blockquote class=\"twitter-tweet\" data-lang=\"en\" data-dnt=\"true\" data-theme=\"dark\"><p lang=\"ja\" dir=\"ltr\"><a href=\"https://t.co/hjYsuvJFMd\">pic.twitter.com/hjYsuvJFMd</a></p>&mdash; atsuya kobayashi (@atsuyakoba) <a href=\"https://twitter.com/atsuyakoba/status/1221912455019782144?ref_src=twsrc%5Etfw\">January 27, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</div>\n\n## joy-con to Python\n\nこう言うと人に驚かれるのだが，僕は任天堂Switchを持っていないのに任天堂Switchのコントローラーであるジョイコンを持っています。なぜならジョイコンだけ買った(買わされた)から。\n\nということで，ジョイコンをmacにつなげて何か遊べないかと考えていたときに，[Qiita: Joy-ConにPythonからBluetooth接続をして6軸センサーと入力情報を取得する](https://qiita.com/tokoroten-lab/items/9a5d81c8f640ecaff7a9#comment-a6875db57d685403e37f)という記事を発見。すぐさま著者が公開していたリポジトリを訪問し，forkし，パッケージ化し，PRを出した（らめっちゃ丁寧なコードレビューをしてもらい感動した）。それが以下のリポジトリ。\n\n<blockquote class=\"embedly-card\"><h4><a href=\"https://github.com/tokoroten-lab/joycon-python\">tokoroten-lab/joycon-python</a></h4><p>driver for Joy-Con (Nintendo Switch). Contribute to tokoroten-lab/joycon-python development by creating an account on GitHub.</p></blockquote>\n<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script>\n\n今ではPyPiへの公開もされており，`pip install joycon-python`で使える。\n\n## joy-con to osc\n\n次に，ジョイコンの状態を監視してOSCを送るスクリプトを作成した。それも以下のリポジトリとして公開している。\n\n<blockquote class=\"embedly-card\"><h4><a href=\"https://github.com/atsukoba/joycon-osc\">atsukoba/joycon-osc</a></h4><p>Send OSC (Open Sound Control) by Joy-Con (Nintendo Switch). Contribute to atsukoba/joycon-osc development by creating an account on GitHub.</p></blockquote>\n\n## joy-con to Max/MSP\n\nOSCを飛ばす準備をしたら，あとはMax上で受け取って音にする。\n\n<div style=\"margin:0 auto;width:fit-content;\">\n<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-theme=\"dark\"><p lang=\"und\" dir=\"ltr\"><a href=\"https://t.co/iW8arvdzSw\">pic.twitter.com/iW8arvdzSw</a></p>&mdash; atsuya kobayashi (@atsuyakoba) <a href=\"https://twitter.com/atsuyakoba/status/1220526326647386112?ref_src=twsrc%5Etfw\">January 24, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</div>\n","---\ndescription: \"\"\ntitle: \"Jupyter NotebookのCustom CSS\"\nslug: jupyterstyle\ndate: 2019-04-24 10:33:59\ncategory: \"Tech Blog\"\ntags: [Jupyter Notebook, CSS]\n---\n\nJupyter Notebookでは`~/.jupyter/custom/custom.css`にCSSを記述すれば自由にスタイルを変えられる。テーマを変更するのではなく，自前でCSSを書く。  \n例えば[あなたの生産性を向上させるJupyter notebook Tips](https://recruit-tech.co.jp/blog/2018/10/16/jupyter_notebook_tips/#b24)では，シンタックスハイライトまで変更している。\n\n<!-- more -->\n\n例えば，以下のCSSを当てると\n\n<script src=\"https://gist.github.com/atsukoba/beb7ec3fd1927dacf2f6df4b0f209f22.js\"></script>\n\n### Before\n\n![before style](https://i.gyazo.com/975ecbdd77872c8792108ed679284c91.png)\n\n### After\n\n![after style](https://i.gyazo.com/5567d5a7d74c2989ba069c3563b6061a.png)\n\nきゃー便利。`animate.css`とかで無駄なパララックスを実装して遊んでも良さそうだ。ただJupyter Labはマークアップの構造がそもそもかなり違うため，流用はでき無さそう。\n\n","---\ndescription: \"\"\ntitle: \"Wikipediaから検索するLINE botを作った\"\nslug: line-wikipedia\ndate: 2019-05-04 00:26:20\ncategory: \"Tech Blog\"\ntags: [Python, LINE Bot]\n---\n\n`flask`, `line-bot-sdk` と `wikipedia`で作って，`heroku`にデプロイします。\n\n<a href=\"http://nav.cx/9xRAMW8\" >ぜひ使って下さい。</a><a href=\"http://nav.cx/9xRAMW8\" style=\"width: 120px;height: 35px;display: inline-block;border-radius: 10px;background-image: url(https://scdn.line-apps.com/n/line_add_friends/btn/ja.png);background-size: cover;\">\n</a>\n\n<!-- more -->\n\n---\n\n## 完成図\n\n![screenshot](https://repository-images.githubusercontent.com/184452650/ee9d3b80-6cab-11e9-9261-01e61f18fa3c)\n\nレポジトリは[こちら](https://github.com/atsukoba/Wikipedia-LINEbot)\n\n---\n\n## 準備\n\n`pip install -r requirements.txt`させたいので，上記３つを requirements.txt へ記述し，heroku の設定と LINE@の設定を終わらせておく (アクセストークンとチャンネルシークレットあたりを入手しておく)。`runtime.txt`と`procfile`を置く。基本[Heroku で LINE BOT(python)を動かしてみた](https://qiita.com/akabei/items/38f974716f194afea4a5)を真似た。\n\n---\n\n## Wikipedia について\n\nみんなだいすき Wikipedia。\n\n```bash\npip instal wikipedia\n```\n\nで入るライブラリである[Wikipedia](https://pypi.org/project/wikipedia/)は非常に便利で，Python 用の[Media Wiki API](https://ja.wikipedia.org/w/api.php)のラッパーだと解釈している。`requests`で API 叩いて，`BeautifulSoup4`か何かでマークアップをバラして，返してくれるものだったはず。\n\n```python\nimport wikipedia\n\nwikipedia.set_lang(\"ja\")\n```\n\nで日本語 Wikipedia に設定した後，\n\n```python\nwikipedia.search(\"文字列\")\n```\n\nをすることで各`ページ名`のリストが返り，書く Wikipedia のページはその名前(タイトル)が ID となっており，\n\n```python\nwikipedia.page(\"ページ名\")\n```\n\nで`wikipedia.WikipediaPage`オブジェクトを取得できる。この page オブジェクトが`categories`, `links`, `content`, `summary`などの attributes をもっており，これらは基本的に URL か文字列かのリストである。\n\n```python\n>>> help(wikipedia.WikipediaPage)\n>>>\n\"\"\"\ncategories\n    List of categories of a page.\ncontent\n    Plain text content of the page, excluding images, tables, and other data.\ncoordinates\n    Tuple of Decimals in the form of (lat, lon) or None\nimages\n    List of URLs of images on the page.\nlinks\n    List of titles of Wikipedia page links on a page.\n    Only includes articles from namespace 0, meaning no Category, User talk, or other meta-Wikipedia pages.\nparent_id\n    Revision ID of the parent version of the current revision of this\n    page. See ``revision_id`` for more information.\nreferences\n    List of URLs of external links on a page.\n    May include external links within page that aren't technically cited anywhere.\nrevision_id\n    Revision ID of the page.\n    The revision ID is a number that uniquely identifies the current\n\"\"\"\n```\n\n今回つくる LINE Bot では，検索単語に対して取得した候補の中から 1 ページ選び，そのページの summary (タイトル直後の概要・OGP とかに表示される?)とページへのリンクを LINE トークルームにかえしてあげよう，というものを作ることにした。\n\n---\n\n## ファイルとか\n\n```\n.\n├── Procfile\n├── README.md\n├── __pycache__\n│   ├── app.cpython-36.pyc\n│   └── parser.cpython-36.pyc\n├── app.py\n├── assets\n│   └── img\n│       └── linebot-icon.png\n├── messenger.py\n├── parser.py\n├── requirements.txt\n├── runtime.txt\n└── test.py\n```\n\n---\n\n## `app.py`\n\n次に，`flask`ベースでアプリケーション部分をササっと書きますが，これもほぼコピペ。面倒な部分を`linebot`が隠してくれていて，非常に便利。\n\n```python\nfrom flask import Flask, request, abort\n\nfrom linebot import (\n    LineBotApi, WebhookHandler\n)\nfrom linebot.exceptions import (\n    InvalidSignatureError\n)\nfrom linebot.models import (\n    MessageEvent, TextMessage, TextSendMessage,\n)\n\nimport parser\nimport os\n\napp = Flask(__name__)\n\nYOUR_CHANNEL_ACCESS_TOKEN = os.environ.get(\"YOUR_CHANNEL_ACCESS_TOKEN\")\nYOUR_CHANNEL_SECRET = os.environ.get(\"YOUR_CHANNEL_SECRET\")\n\nline_bot_api = LineBotApi(YOUR_CHANNEL_ACCESS_TOKEN)\nhandler = WebhookHandler(YOUR_CHANNEL_SECRET)\n\n\n@app.route(\"/callback\", methods=['POST'])\ndef callback():\n    # get X-Line-Signature header value\n    signature = request.headers['X-Line-Signature']\n\n    # get request body as text\n    body = request.get_data(as_text=True)\n    app.logger.info(\"Request body: \" + body)\n\n    # handle webhook body\n    try:\n        handler.handle(body, signature)\n    except InvalidSignatureError:\n        print(\"Invalid signature. Please check your channel access token/channel secret.\")\n        abort(400)\n\n    return 'OK'\n\n\n@handler.add(MessageEvent, message=TextMessage)\ndef handle_message(event):\n    line_bot_api.reply_message(\n        event.reply_token,\n        TextSendMessage(text=parser.answer(event.message.text)))\n\n\nif __name__ == \"__main__\":\n    port = int(os.getenv(\"PORT\", 5000))\n    app.run(host=\"0.0.0.0\", port=port)\n```\n\nline-bot-sdk-python の公式リポジトリに，`app.py`として flask でのサンプルが公開されている。\n[[sample] app.py](https://github.com/line/line-bot-sdk-python/blob/master/examples/flask-echo/app.py)\n\nまた，今回はそもそも README にガッツリ載っていたものを使った。[sample code on GitHub](https://github.com/line/line-bot-sdk-python/blob/master/README.rst)\n\n---\n\n### `parser.py`\n\nparser はモジュールの変数として言語設定を持っている。設計として微妙ですかね？モジュール(グローバル)変数は。  \nなんか使い方間違えたりとか，ヘルプ出したい時のための`usage()`は未実装。  \n意外と`WikipediaPage.summary`の文字数が長く，Messaging API の上限を叩いてしまったときのために，1500 文字以上は切っている。\n\n```python\nimport wikipedia\n\n\n# init language setting\nlang = \"ja\"\nwikipedia.set_lang(lang)\n\ndef init() -> None:\n    global lang\n    wikipedia.set_lang(lang)\n\n\ndef tokenize(text: str) -> list:\n    \"\"\"Tokenize input Sentence to list of word\"\"\"\n    splited = text.split()\n    if len(splited) == 1:\n        return splited\n    elif len(splited) == 2:\n        if splited[0] in wikipedia.languages.fn().keys():\n            change_lang(splited[0])\n        return splited[1]\n    else:\n        usage()\n\ndef search(text: str, rank=0) -> \"wikipedia.wikipedia.WikipediaPage\":\n    \"\"\"Search Wikipedia page by Word\n    arg\n    ---\n    rank : int : Return the contents of the search result of the set rank.\n    \"\"\"\n    try:\n        page = wikipedia.page(wikipedia.search(text)[rank])\n    except wikipedia.exceptions.DisambiguationError:\n        page = wikipedia.page(wikipedia.search(text)[rank+1])\n    return page\n\n\ndef encode(page: \"wikipedia.wikipedia.WikipediaPage\", threshold=1500) -> str:\n    \"\"\"Transform data into the text for LINE message\n    \"\"\"\n    summary = page.summary\n    if len(summary) > threshold:\n        summary = summary[:threshold] + \"...\"\n\n    return f\"Result: {page.title}\\n\\n{summary}\\n\\n{page.url}\"\n\n\ndef answer(text: str) -> str:\n    init()\n    word = tokenize(text)\n    page = search(word)\n    return encode(page)\n\n\ndef change_lang(language: str) -> None:\n    wikipedia.set_lang(language)\n    return\n\ndef usage():\n    pass\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.parse_args()\n```\n\n一応ちゃんと**PEP8**スタイルだし，type hints も docstring 書いている。クセにしとおきたい。\n\n---\n\n### デプロイ等\n\n```bash\n$ heroku login\n$ heroku create heroku-line-bot\n$ heroku config:set LINE_CHANNEL_SECRET=\"<Channel Secret>\"\n$ heroku config:set LINE_CHANNEL_ACCESS_TOKEN=\"<アクセストークン>\"\n$ git push heroku master\n```\n\n---\n\n### references\n\n- [LINE Messaging API SDK for Python - GitHub](https://github.com/line/line-bot-sdk-python)\n- [Python で Line bot を作ってみた - Qiita](https://qiita.com/kro/items/67f7510b36945eb9689b)\n- [Messaging API SDK - LINE Developers](https://developers.line.biz/ja/docs/messaging-api/line-bot-sdk/)\n- [Heroku でサンプルボットを作成する - LINE Developers](https://developers.line.biz/ja/docs/messaging-api/building-sample-bot-with-heroku/)\n- [heroku に Flask アプリをデプロイする - Qiita](https://qiita.com/msrks/items/c57e0168fb89f160d488)\n","---\ndescription: \"\"\ntitle: \"複数の.ipynb をまとめて目次生成\"\nslug: nb-table-generator\ndate: 2019-02-16 23:01:27\ncategory: \"Tech Blog\"\ntags: [Python, Jupyter Notebook]\n---\n\n自身のGitHub上で自身の学習記録やボイラープレートをカンペ集として残している([リポジトリ](https://github.com/atsukoba/cheatbooks))のですが，同じディレクトリ直下に複数のノートブックを保存しています。で，その各ノートブック内のMarkdownに記述されている部分を抽出するスクリプトを書きました。\n\n<!-- more -->\n\n### Usage\n\n```shell\n% python nb_table_generator.py\n```\n\nor\n``` python\nimport nb_table_generator\n\nnb_table_generator.main(file_name=\"output_file_name\")\n```\n\n### src\n\n<script src=\"https://gist.github.com/atsukoba/b284847b58c5d4598580dfe9539669e2.js\"></script>","---\ndescription: \"\"\ntitle: \"atsuya.info の移行\"\nslug: old-site-close\ndate: 2019-02-13 16:08:36\ncategory: \"Tech Blog\"\ntags: [WordPress]\n---\n\n以前`WordPress`を用いて`atsuya.info`として公開していた私のプロフィールサイトを，`WordPress`上での静的サイト変換プラグインを用いこのサイトの[/old-info](/old-info)内に公開し，元サイトを閉鎖しました。\n\n<!-- more -->\n\natsuya.info  \n\n![screenshot](ss-atsuya-info.png \"atsuya-info-ss\")\n","---\ndescription: \"\"\ntitle: \"nodejsでローカルにoscを送るwebアプリケーションを作る (SocketIO, Express)\"\nslug: osc-webapp\ndate: 2019-10-08 17:50:42\ncategory: \"Tech Blog\"\ntags: [Open Sound Control, nodejs, express]\n---\n\n誰でもoscを通して作品に参加できるようなwebアプリケーションをプロトタイピングしました。[リポジトリはこちら](\"https://github.com/atsukoba/osc-webapp\")。\n\n<!-- more -->\n\n## OSC (Open Sound Control)\n\nOSCとは: [opensoundcontrol.org](http://opensoundcontrol.org/) や[wikipedia](https://ja.wikipedia.org/wiki/OpenSound_Control)を参照。\n\nyoppa.orgの[openFramewoks – OSC (Open Sound Control) を利用したネットワーク連携](https://yoppa.org/ma2_10/2279.html)が非常にためになる。\n\nUDP上でMIDIみたいなものをMax/MSPに送ったりできるので非常に便利。今回はこいつをLAN上だけならずインターネット上のスマートフォンからローカルに受け付ける，展示をよりインタラクティブにするためのツールのプロトタイピングを行う。\n\n(以下リポジトリを参照していただければローカルでアプリケーション動かせます）\n\n<blockquote class=\"embedly-card\"><h4><a href=\"https://github.com/atsukoba/osc-webapp\">atsukoba/osc-webapp</a></h4><p>Serve OSC from www. Contribute to atsukoba/osc-webapp development by creating an account on GitHub.</p></blockquote>\n<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script>\n\n## 概観\n\nnodejs/expressでサーバを立てて，軽くて双方向に使えるwebsocketでユーザのアプリケーション上での動きを捉える。localhostに立てたサーバをngrokで公開し，そのURL(とローカルのIPアドレス)をQRコードに出力するところまでを実装する。\n\n軽くフロントを書いてデモをつくり，簡単なボタンとそのボタンに対応したメッセージをローカルのoscに送れるかを確認する。\n\n![alt](oscweb_screenshots.png \"デモのスクリーンショット\")\n\n\n### express\n\n```shell\nnpm install express-generator -g\nexpress --view=ejs osc-webapp\ncd osc-webapp\nnpm install\n```\n\n`socket.io`を使用する。\n\n```javascript\nconst app = express();\nconst http = require('http').Server(app);\nconst io = require('socket.io')(http);\n```\n\n### osc\n\n`node-osc`([npm: node-osc](https://www.npmjs.com/package/node-osc))を利用する。利用例としては以下のような感じ\n\n```javascript\nconst osc_portnum = 5050;\nconst client = new osc.Client('127.0.0.1', osc_portnum);\n\nio.of('osc').on('connection', (socket) => {\n  socket.on('message', (obj) => {\n    console.log('osc: ' + obj);\n    obj = JSON.parse(obj)\n    let sendObj =  new osc.Message(obj.address);\n    sendObj.append(obj.args);\n    client.send(sendObj);\n    let dt = new Date();\n    io.of('osc').send(`${dt.toFormat(\"HH24:MI:SS\")} : osc message received: ${obj.args}`);\n  });\n});\n```\n\n### qrcode\n\n`os`, `qrcode`([npm: qrcode](https://www.npmjs.com/package/qrcode)) を用いて，ローカルIPアドレスと`ngrok`([npm: ngrok](https://www.npmjs.com/package/ngrok))で生成したURLをQRにする。\n\n```javascript\nconst ngrok = require('ngrok');\nconst qrcode = require('qrcode');\n\n// get local ip addresses\nlet interfaces = os.networkInterfaces();\nlet addresses = [];\nfor (let k in interfaces) {\n  for (let k2 in interfaces[k]) {\n    let address = interfaces[k][k2];\n    if (address.family === 'IPv4' && !address.internal) {\n        addresses.push(address.address);\n    }\n  }\n}\nconsole.log(`local ip addresses: ${addresses}`);\nconsole.log(`FOR LOCAL NEWORK PARTICIPANTS`);\nqrcode.toString(`http://${addresses[0]}:${portnum}`, {type: 'terminal'}, (err, str) => {\n  console.log(str);\n});\n\n// make ngrok tunnel\nconsole.log(`FOR WWW PARTICIPANTS`);\n(async () => {\n  let url = await ngrok.connect(portnum);\n  console.log('ngrok URL: ' + url);\n  qrcode.toString(url, {type: 'terminal'}, (err, str) => {\n    console.log(str);\n  });\n})();\n```\n\n### つかう\n\n```shell\nnpm start\n```\n\nこれでQRコードが生成されるので，それをシェアすればoscを送れる。同一LANにいるなら，上部のQRコードでおｋ。configファイルでポート番号を指定し，デモはクライアント側のmain.jsで(今は)送るoscメッセージをハードコードしているので，適宜それを編集して使っていただければと思う。\n\n![gif](https://i.gyazo.com/3872867c437f9bb2db573f1f3f2b69d1.gif)\n\n### reference\n\n- [Qiita: node.jsとProcessingをOSCでやりとり](https://qiita.com/tkyko13/items/d219a509d8367e272055)\n- [yoppa.org: Processing Libraries 3 : oscP5 – OSCによるアプリケーション間通信](https://yoppa.org/sfc_design16/7927.html)\n","---\ndescription: \"\"\ntitle: \"Processingのvscode開発環境を構築(Mac)\"\nslug: processing-on-vscode\ndate: 2019-08-25 07:16:23\ncategory: \"Tech Blog\"\ntags: [Processing, Visual Studio Code]\n---\n\nProcessingのIDEが非常にイヤなので，まずは[Qiita: ProcessingをVisual Studio Codeで動かしたい](https://qiita.com/jacynthe/items/d31eaa77496295c10556)を参照し設定する。しかしこの記事のやり方だと，1スケッチ毎に`.vscode`による設定をしなければならずイヤなので，例えば[Processingでゼロから学ぶプログラミング・ビジュアルアートの公式リポジトリ](https://github.com/cocopon/zero-pde)なんかをcloneしてきて試す時に，プロジェクトフォルダに内包されている複数のスケッチを即時実行できるように改良したメモです。\n\n<!-- more -->\n\n## 準備\n\nまずは上述の[Qiita記事](https://qiita.com/jacynthe/items/d31eaa77496295c10556)通りにセッティングを行う。そしたらProcessingのインストール。ラクなので`Homebrew`を使う。\n\n### install.sh\n\n```shell\n# homebrew\nif !(type \"brew\" > /dev/null 2>&1); then\n    echo \"install HomeBrew...\"\n    ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" < /dev/null 2> /dev/null ; brew install caskroom/cask/brew-cask 2> /dev/null\n\nelse\n    echo \"Homebrew is already installed\"\nfi\n\nif !(type \"processing-java\" > /dev/null 2>&1); then\n    brew tap caskroom/cask\n    brew install brew-cask\n    echo \"installing Processing via Homebrew...\"\n    brew cask install -v processing\n\n    echo \"Open Processing and install processing-java (from menu bar > Tools > install processing-java)\"\n    echo \"input path to Processing.app: \"\n    read pjpath\n    echo \"adding path\"\n    sudo ln -s ${pjpath}/processing-java /usr/local/bin/\nelse\n    pjpath=$(which processing-java)\n    echo \"processing-java is already installed : ${pjpath}\"\nfi\n\necho \"add path to vscode setting (tasks.json)\"\nsed -i -e \"s|\\\"command\\\":.*|\\\"command\\\": \\\"${pjpath}\\\",|g\" .vscode/tasks.json\n```\n\nそして，生成・編集された`tasks.json`の`\"args\"`の`\"--sketch\"`部分を，[visualstudio.com: Variables Reference](https://code.visualstudio.com/docs/editor/variables-reference)を頼りに編集する。\n\n### .vscode/tasks.json\n\n```json\n\"--sketch=${workspaceRoot}/${relativeFileDirname}\"\n```\n\nこれによりスケッチフォルダのパスがちゃんと渡される。\n\n### Variable Reference\n\n```txt\n${workspaceFolder} - the path of the folder opened in VS Code\n${workspaceFolderBasename} - the name of the folder opened in VS Code without any slashes (/)\n${file} - the current opened file\n${relativeFile} - the current opened file relative to workspaceFolder\n${relativeFileDirname} - the current opened file's dirname relative to workspaceFolder\n${fileBasename} - the current opened file's basename\n${fileBasenameNoExtension} - the current opened file's basename with no file extension\n${fileDirname} - the current opened file's dirname\n${fileExtname} - the current opened file's extension\n${cwd} - the task runner's current working directory on startup\n${lineNumber} - the current selected line number in the active file\n${selectedText} - the current selected text in the active file\n${execPath} - the path to the running VS Code executable\n```\n\nこれにより，プロジェクトフォルダ直下の`.pde`でなくても，`Command + Shift + B`で実行できる。ウレシイ。\n\nここで，試しに`git submodule add git@github.com:cocopon/zero-pde.git`をして，Processingでゼロから学ぶプログラミング・ビジュアルアートを試す等すると良いかも。\n","---\ndescription: \"\"\ntitle: \"bashプロンプトメモ\"\nslug: ps1\ndate: 2019-04-29 00:00:53\ncategory: \"Tech Blog\"\ntags: [shellscript, bash]\n---\n\nGit のブランチをプロンプトに表示したかったので，[プロンプトをカスタマイズして git ブランチを表示する](https://qiita.com/caad1229/items/6d71d84933c8a87af0c4)をもとに，`~/.bashrc`の`PS1`(The primary prompt string) を変更したのでメモ。\n\n---\n\n<script src=\"https://gist.github.com/atsukoba/369f8afa9bde30ceafce2d4f3b087a2c.js\"></script>\n\n以上を設定し，\n\n![my prompt](https://i.gyazo.com/1aa55461979ca2a5e392e0bf6be39425.png)\n\nこうなった。\n\n---\n\n## 備忘録\n\n[2.5. Bash Prompt Escape Sequences](http://tldp.org/HOWTO/Bash-Prompt-HOWTO/bash-prompt-escape-sequences.html)によると，以下の通り。\n\n- `\\h` => ホスト名\n- `\\u` => ユーザ名\n- `\\w` => ディレクトリ（フルパス）\n- `\\W` => ディレクトリ\n- `\\t` => 時間 (24 形式)\n- `\\T` => 時間 (12 形式)\n- `\\@` => AM / PM\n- `\\d` => 日付\n- `\\D` => 日時\n- `\\#` => コマンド番号\n- `\\!` => ヒストリ番号\n- `\\n` => 改行\n\n表示としては，\n\n```bash\n[<コマンド番号>(<ヒストリ番号>)] <時間 HH:MM:SS> <user> at <directory> [<branch>]\n```\n\nとなる。\n\n`<branch>`の部分では，`parse_guit_branch`を呼んでいて，その内部がでは`git branch --no-color`の結果を`sed`で置換，エラー(`2`)を[`/dev/null`](https://ja.wikipedia.org/wiki//dev/null)へ捨てている。\n\nまた，上記記事にもあるが，色設定として以下の変数化も使える\n\n```shellscript\nlocal  BLUE=\"\\[\\e[1;34m\\]\"\nlocal  RED=\"\\[\\e[1;31m\\]\"\nlocal  GREEN=\"\\[\\e[1;32m\\]\"\nlocal  WHITE=\"\\[\\e[00m\\]\"\nlocal  GRAY=\"\\[\\e[1;37m\\]\"\n```\n\n---\n\n### ちなみに\n\n`PS2`(The secondary prompt string)も設定できるみたいだが面倒なので放置。\n","---\ndescription: ''\ntitle: 'pykakasi, mecab-python3等のメモ。'\nslug: pykakasi-mecab-python\ndate: 2019-07-15 04:54:40\ncategory: 'Tech Blog'\ntags: [Python, Qiita]\n---\n\n[「**ゴー ☆ ジャス（宇宙海賊）をつくる**」](https://qiita.com/jg43yr/items/30defcdb69163612fc27)という，~~お笑い芸人~~[宇宙海賊ゴー ☆ ジャス](https://ja.wikipedia.org/wiki/%E3%82%B4%E3%83%BC%E2%98%86%E3%82%B8%E3%83%A3%E3%82%B9)のネタ生成プログラム(Python)に関する記事を執筆し，初 Qiita 投稿でデイリートレンド１位いただきました。本稿では主に利用したパッケージ詳細のメモです。<a href=\"https://twitter.com/gorgeous55555?ref_src=twsrc%5Etfw\" class=\"twitter-follow-button\" data-show-count=\"false\">Follow @gorgeous55555</a><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n<!-- more -->\n\n![screenshot](https://i.gyazo.com/6c239b85b1b195b7ee2f693751d1c763.png)\n\n---\n\n## packages\n\n- requirements.txt\n\n```txt\npykakasi==1.0\nmecab-python3==0.7\npython-Levenshtein==0.12.0\n```\n\n---\n\n## pykakasi\n\n- usage\n\n`H`が hiragana, `K`が katakana, `A`が alphabet\n\n```python\nimport pykakasi.kakasi as kakasi\n\nkakasi = kakasi()\nkakasi.setMode(\"H\",\"a\") # default: Hiragana -> Roman\nkakasi.setMode(\"K\",\"a\") # default: Katakana -> Roman\nkakasi.setMode(\"J\",\"a\") # default: Japanese -> Roman\nkakasi.setMode(\"r\",\"Hepburn\") # default: use Hepburn Roman table\nkakasi.setMode(\"s\", True) # default: Separator\nkakasi.setMode(\"C\", True) # default: Capitalize\nconv = kakasi.getConverter()  # instantiate Converter\nresult = conv.do(text)  # romanize\n```\n\n---\n\n## mecab-python\n\n[MeCab](https://taku910.github.io/mecab/)の Python ラッパ。\n\n### MeCab on docker\n\n- Dockerfile\n\n```Dockerfile\nRUN apt-get update \\\n    && apt-get install -y mecab \\\n    && apt-get install -y libmecab-dev \\\n    && apt-get install -y mecab-ipadic-utf8\\\n    && apt-get install -y git\\\n    && apt-get install -y make\\\n    && apt-get install -y curl\\\n    && apt-get install -y xz-utils\\\n    && apt-get install -y file\\\n    && apt-get install -y sudo\\\n    && apt-get install -y wget\n\nRUN git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\\\n    && cd mecab-ipadic-neologd\\\n    && bin/install-mecab-ipadic-neologd -n -y\n\nRUN apt-get install -y software-properties-common vim\nRUN add-apt-repository ppa:jonathonf/python-3.6\nRUN apt-get update\n\nRUN apt-get install -y build-essential python3.6 python3.6-dev python3-pip python3.6-venv\nRUN python3.6 -m pip install pip --upgrade\nRUN pip install mecab-python3\n```\n\n- 出力のフォーマット\n\n`表層形\\t品詞,品詞細分類1,品詞細分類2,品詞細分類3,活用型,活用形,原形,読み,発音`\n\n#### 出力結果処理\n\n```python 入力文\nimport MeCab\ntext = \"慶應義塾大学湘南藤沢キャンパス\"\nT = MeCab.Tagger(\"\")\n```\n\n- 表層系 + その他情報のタプル\n\n```python\nparsed = [[l.split('\\t')[0], tuple(l.split('\\t')[1].split(','))] for l in T.parse(text).splitlines()[:-1]]\n```\n\n```python 結果\n[['慶應義塾', ('名詞', '固有名詞', '組織', '*', '*', '*', '慶應義塾', 'ケイオウギジュク', 'ケイオーギジュク')],\n ['大学', ('名詞', '一般', '*', '*', '*', '*', '大学', 'ダイガク', 'ダイガク')],\n ['湘南', ('名詞', '固有名詞', '地域', '一般', '*', '*', '湘南', 'ショウナン', 'ショーナン')],\n ['藤沢', ('名詞', '固有名詞', '地域', '一般', '*', '*', '藤沢', 'フジサワ', 'フジサワ')],\n ['キャンパス', ('名詞', '一般', '*', '*', '*', '*', 'キャンパス', 'キャンパス', 'キャンパス')]]\n```\n\n- 全情報のタプル\n\n`re`で一気に分ける\n\n```python\nimport re\nparsed = [tuple(re.split(r\"[\\t,]\", l)) for l in T.parse(text).splitlines()[:-1]]\n```\n\n```python 結果\n[('慶應義塾', '名詞', '固有名詞', '組織', '*', '*', '*', '慶應義塾', 'ケイオウギジュク', 'ケイオーギジュク'),\n ('大学', '名詞', '一般', '*', '*', '*', '*', '大学', 'ダイガク', 'ダイガク'),\n ('湘南', '名詞', '固有名詞', '地域', '一般', '*', '*', '湘南', 'ショウナン', 'ショーナン'),\n ('藤沢', '名詞', '固有名詞', '地域', '一般', '*', '*', '藤沢', 'フジサワ', 'フジサワ'),\n ('キャンパス', '名詞', '一般', '*', '*', '*', '*', 'キャンパス', 'キャンパス', 'キャンパス')]\n```\n\n#### MeCab: 分かち書き\n\n```python\nimport MeCab\nwakati = MeCab.Tagger(\"-Owakati\")\nwakati.parse(\"慶應義塾大学湘南藤沢キャンパス\").split()\n```\n\n#### Chasen スタイル\n\n```python\nchasen = MeCab.Tagger(\"-Ochasen\")\nprint(chasen.parse(\"pythonが大好きです\"))\n```\n\n```text\npython　python　　python　名詞-固有名詞-組織\nが　　　ガ　　　　が　　　助詞-格助詞-一般\n大好き　ダイスキ　大好き　名詞-形容動詞語幹\nです　　デス　　　です　　助動詞　特殊・デス　基本形\nEOS\n```\n\n#### その他\n\n- `-Oyomi`オプションで読みの出力。ただ分かち書きがされない。\n\n","---\ndescription: \"\"\ntitle: 「sunday evening downer」を公開\nslug: sunday-evening\ndate: 2019-07-14 23:46:04\ncategory: Music\ntags: [SoundCloud, Rock]\n---\n\n先日中古のFenderJapan JB75を購入したので，その記念に超久しぶりに楽曲制作(Gt, Ba -> Ableton Live)しました。日曜夕方のダルい感じをお楽しみください。\n\n<iframe width=\"100%\" height=\"166\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/650983226&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true\"></iframe>\n\n<!-- more -->\n\n## Playlist\n\n先輩にギターのフレーズだけ渡してRemixしてもらったものも含めたプレイリストもあります。\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/playlists/825452744&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true\"></iframe>","---\ndescription: \"\"\ntitle: \"ブラウザ上で録音できるツールをflask + recorder.js + p5.js on TypeScript で作る\"\nslug: ts-p5-webapp\ndate: 2019-11-4 01:27:35\ncategory: \"Tech Blog\"\ntags: [p5.js, Recorder.js, Web Audio API, TypeScript]\n---\n\nWeb Audio APIのラッパーであるrecorder.jsを用いて簡易レコーダーを作成します。ブラウザ版Processingであるp5.jsをtsで書いてUI実装します。\n\n<!-- more -->\n\n> *フィールドレコーディング：スタジオ外での自然音や環境音の録音*\n> 自然音や環境音を手軽に集めたい，そしてそれをPCへ送りリアルタイムに処理したい，といったニッチな要望に応えるものを作った感じです\n\n## 完成イメージ\n\nイメージといってもスクリーンショットなんでこういう感じで動きます。\n\n![animation screenshot](https://i.gyazo.com/6825cb4c65c8d1c4e7f8f7a3a6a357d4.gif)\n\n(たぶん)ササっと環境構築して動かせるので興味ある方は是非。\n\n## recorderjsでフロント側で音声録音する\n\nGitHub: <https://github.com/mattdiamond/Recorderjs>\n\nまずデモはこちら[Simple Recorder.js demo](https://addpipe.com/simple-recorderjs-demo/)\n\nWeb Audio APIのラッパーみたいな感じでしょうか。AudioNodeのインスタンスを渡せば簡単に録音スタート・ストップ・保存ができる，という優れモノ。\n\n以下のような感じで録音開始の関数定義ができるので，任意のイベントで呼べば良い。\n\n```typescript\nlet recorder : Recorder\n\nconst startUserMedia = (stream : MediaStream) => {\n  audio_context = new AudioContext\n  let input : AudioNode = audio_context.createMediaStreamSource(stream)\n  recorder = new Recorder(input)\n}\n\nconst startRecording = () => {\n  recorder && recorder.record()\n}\n```\n\nで，この`Recorder.exportWAV()`メソッド一発でwavのBlobオブジェクトが手に入るので，ソレをajaxでPOSTしてあげれば良い。\n\n```typescript\nrecorder && recorder.exportWAV((blob : Blob) => {\n  let url = URL.createObjectURL(blob)\n  let fd = new FormData()\n  fd.append('data', blob)\n  $.ajax({\n    type: 'POST',\n    url: '/',\n    data: fd\n  }).done((data) => {\n    recorder.clear()\n    }\n  )\n})\n```\n\n## flaskでPOSTされたwavファイルを保存する\n\nflask側ではこんな感じに書けば良い。\n\n```python\nfrom flask import Flask, jsonify, request\n\n\n@app.route('/', methods=['POST'])\ndef uploaded_wav():\n    fname = \"sounds/\" + datetime.now().strftime('%m%d%H%M%S') + \".wav\"\n    with open(f\"{fname}\", \"wb\") as f:\n        f.write(request.files['data'].read())\n    print(f\"posted sound file: {fname}\")\n    return jsonify({\"data\": fname})\n```\n\nこれで`sounds/`直下に`1104235900.wav`みたいなファイルがどんどん溜まっていく。\n\n## 保存されたファイルのパスをoscで送る\n\n個人的にこのアプリケーションをパフォーマンスで使用したいので，サウンドファイルが保存されたタイミングでoscにメッセージを飛ばしてみる。コレで例えばサーバとなっているローカルのPCでMax/MSPやMax for Liveを用いたリアルタイムでのサウンドファイル読み込みがラクになる（と信じている）\n\n`pythonosc`というパッケージを用いる。(`pip install python-osc`で入る)\n\npython-osc PyPI: <https://pypi.org/project/python-osc/>\n\n```python\nfrom pythonosc import dispatcher, osc_message_builder, osc_server, udp_client\n\n\naddress = \"127.0.0.1\"\nport = 5050\nclient = udp_client.UDPClient(address, port)\n\n\ndef send_osc(msg):\n    msg_obj = osc_message_builder.OscMessageBuilder(address=address)\n    msg_obj.add_arg(msg)\n    client.send(msg_obj.build())\n```\n\nこれで良い。あとは上述の`uploaded_wav()`内で`send_osc(fname)`してあげれば，ファイルパスがメッセージとして届く。Maxなら`[udpreceive 5050]`しておけばopen&sfplay~して再生できる。\n\n## p5.js\n\np5js.org: <https://p5js.org/>\n\nDOMがいじれるProcessingという感じで，Canvas要素に描画するのでCSSで複雑なアニメーションを描いているとかしなくても，canvasが動くブラウザなら良いしこっちのがラクかもしれないです。また，Web Editor(<https://editor.p5js.org/>) というものがあり，環境構築ナシで挙動が試せるので非常にとっかりやすいと思います。\n\nTypeScriptを導入するなら，まず以下のリポジトリを使うべきです（めっちゃラクだった）\n\n<blockquote class=\"embedly-card\"><h4><a href=\"https://github.com/Gaweph/p5-typescript-starter\">Gaweph/p5-typescript-starter</a></h4><p>Base starter project using p5js and typescript: Contribute to Gaweph/p5-typescript-starter development by creating an account on GitHub.</p></blockquote>\n\nかつ，以下のエントリを参考にしました\n\n- [TypeScript+webpackでProcessing(p5.js)の環境を構築する - Qiita](https://qiita.com/uchiko/items/744d7559d37973a959ea)\n- [CreativeCoding用にP5.jsがTypeScriptで書ける環境をつくった。 - Qiita](https://qiita.com/y___k/items/429e7095ef638a515b07)\n\nあとは，ササっと書いていくだけです。例としてUIの録音ボタンの部分のクラスをおいておきます…\n\n```typescript\nclass Button {\n\n  private w: number\n  private h: number\n  private centerX: number\n  private centerY: number\n  private radius: number\n  private isRecording: boolean\n  private rectCircleRatio : number\n  private progress : number // 0 ~ 300 value (about 5s)\n\n  constructor(w: number, h: number, size: number) {\n    this.w = w\n    this.h = h\n    this.centerX = w / 2\n    this.centerY = h / 2\n    this.radius = size\n    this.isRecording = false\n    this.rectCircleRatio = size / 2\n    this.progress = 0\n  }\n\n  isTouched(x: number, y: number) {\n    if (((x - this.centerX) ** 2 + (y - this.centerY) ** 2) < this.radius ** 2) {\n      return true\n    }\n    return false\n  }\n\n  switchRecording() {\n    this.isRecording = !this.isRecording\n    console.log(`switched to recording: ${this.isRecording}`)\n    if (this.isRecording) {\n      startRecording()\n    } else {\n      this.progress = 0\n      stopRecording()\n    }\n  }\n\n  draw() {\n    if (this.progress == 300) {\n      this.progress = 0\n      this.switchRecording()\n    }\n    if (this.isRecording) {\n      if (this.rectCircleRatio > 5) {\n        clear();\n        this.rectCircleRatio -= 5;\n      }\n      this.progress ++\n    } else {\n      if (this.rectCircleRatio <= this.radius / 2) {\n        clear();\n        this.rectCircleRatio += 5;\n      }\n    }\n    drawCircleUI(this.progress * 2 * PI / 300)\n    noStroke();\n    fill(mainColor);\n    rect(\n      this.centerX - this.radius / 2,\n      this.centerY - this.radius / 2,\n      this.radius, this.radius, \n      this.rectCircleRatio\n    );\n    // text\n    fill(white)\n    textAlign(CENTER, CENTER);\n    textSize(16);\n    if (this.isRecording) {\n      text('STOP', \n      this.centerX,\n      this.centerY);\n    }else {\n      text('REC', \n      this.centerX,\n      this.centerY);\n    }\n  }\n}\n```\n\n## リポジトリ\n\n<blockquote class=\"embedly-card\" data-card-controls=\"0\"><h4><a href=\"https://github.com/atsukoba/AudioSampleRecorder\">atsukoba/AudioSampleRecorder</a></h4><p>Audio recording on the Web using Web Audio API for remote real-time environmental sound collection. python3 and packages listed in requirements.txt nodejs and packages listed in package.json tmux ngrok recorder-js git clone -r https://github.com/atsukoba/AudioSampleRecorder.git npm install sh ngrok-install.sh then put your ngrok auth-token if using pip and HomeBrew, run this prepared script.</p></blockquote>\n<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script>\n\n実際に活用できるので気が向いたらどうぞ。[osc-webapp]()と同じく，ngrokでhttpsトンネルほって公開してます。(httpsじゃないとWeb Audio APIが使えない)\n","---\ndescription: \"\"\ntitle: \"Keio SFC Open Research Forum 2019で作品発表\"\nslug: x-sampling-orf\ndate: 2019-11-28 00:30:02\ncategory: \"Tech Blog\"\ntags: [cclab, x-sampling]\n---\n\nSFC徳井研究室（Computational Creativity Lab）内プロジェクトであるx-samplingの作品である**Real-time Field Recording Ensemble**を展示発表しました。\n\n[ORF2019: x-sampling](https://cclab.sfc.keio.ac.jp/projects/x-sampling/)\n[GitHub repo](https://github.com/sfc-computational-creativity-lab/x-sampling-field-recording-ensemble)\n\n<!-- more -->\n\n![system](orf_02-1-1024x854.png)\n"],"title":"Nextjs Blog Site","description":"A Simple Markdown Blog build with Nextjs."},"__N_SSG":true}