{"pageProps":{"content":"\nOptunaを使ってみる練習として，Doc2Vecを用いてテキスト分類をするやつをサクっと書きました。  \n出力はモデルのaccuracy，F1と，`pyplot`でのConfusion Matrixを出力します。\n\n<!-- more -->\n\nラベルデータを下記の形で用意します\n\n| DOCUMENT_FILE_NAME(id) | LABEL(labels) |\n|:----------------------:|:-------------:|\n|        foo.txt         |      bar      |\n|        bar.txt         |      foo      |\n\n使い方は，`% python document_SVClassifier.py -h`で。\n\n各テキストデータ毎に分類を行います。\n\n### Source ([github](https://gist.github.com/atsukoba/b33967dee47e92f58240a3a544d0650b))\n\n\n```python\n# Author: Atsuya Kobayashi @atsuya_kobayashi\n# 2019/02/15 17:20\n\n\"\"\"Support Vector Document Classifier with doc2vec & Optuna\n- .csv label file must be in the form of following style\n|DOCUMENT_FILE_NAME(id)|LABEL(labels)|\n|----------------------|-------------|\n|       foo.txt        |     bar     |\n|       bar.txt        |     foo     |\n\"\"\"\n\nimport argparse\nimport itertools\nimport optuna\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVC\nfrom gensim.models import Doc2Vec\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n\n# parameters\nPATH_TO_CSVFILE = \"\"\nTEXTFILE_TARGET_DIR = \"/\"\nPATH_TO_PRETRAINED_DOC2VEC_MODEL = \"\"\nN_OPTIMIZE_TRIAL = 20\nUSE_MORPH_TOKENIZER = False\n\ndef plot_confusion_matrix(cm, classes, normalize=False,\n                          title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    return\n\n\n# for Optuna\ndef obj(trial):\n    # C\n    svc_c = trial.suggest_loguniform('C', 1e0, 1e2)\n    # kernel\n    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n    # SVC\n    clf = SVC(C=svc_c, kernel=kernel)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    # 3-fold cross validation\n    score = cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3)\n    accuracy = score.mean()\n    return 1.0 - accuracy\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description='Train a Support Vector Sentence Classifier')\n    parser.add_argument('csv', help='PATH TO CSVFILE')\n    parser.add_argument('dir', help='TEXTFILE TARGET DIRECTORY')\n    parser.add_argument('model', help='PATH TO PRETRAINED DOC2VEC MODEL FILE')\n    parser.add_argument(\"-N\", \"--n_trial\", dest='n', default=20, type=int,\n                        help='N OF OPTIMIZE TRIALS (Default is 20times)')\n    parser.add_argument(\"-M\", \"--mecab\", dest='mecab', action='store_true',\n                        help='USE MECAB Owakati TAGGER')\n    args = parser.parse_args()\n    PATH_TO_CSVFILE = args.csv\n    TEXTFILE_TARGET_DIR = args.dir\n    PATH_TO_PRETRAINED_DOC2VEC_MODEL = args.model\n    N_OPTIMIZE_TRIAL = args.n\n    USE_MORPH_TOKENIZER = args.mecab\n\n    m = MeCab.Tagger(\"-Owakati\")\n    df = pd.read_csv(PATH_TO_CSVFILE)\n\n    documents = []\n    for fname in tqdm(df.id, desc=\"Reading Files\"):\n        with open(TEXTFILE_TARGET_DIR + fname) as f:\n            if USE_MORPH_TOKENIZER:\n                doc = m.parse(f.read()).strip().split()\n            else:\n                doc = f.read().strip().split()\n        documents.append(doc)\n\n    model = Doc2Vec.load(PATH_TO_PRETRAINED_DOC2VEC_MODEL)\n    document_vectors = [model.infer_vector(s) for s in tqdm(documents)]\n\n    X_train, X_test, y_train, y_test = train_test_split(document_vectors, df.labels,\n                                                        test_size=0.5, random_state=42)\n\n    study = optuna.create_study()\n    study.optimize(obj, n_trials=N_OPTIMIZE_TRIAL)\n    # fits a model with best params\n    clf = SVC(C=study.best_params[\"C\"], kernel=study.best_params[\"kernel\"])\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    # Compute confusion matrix\n    cnf_matrix = confusion_matrix(y_test, y_pred)\n    np.set_printoptions(precision=2)\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=data.categories,\n                          title='Confusion matrix, without normalization')\n    plt.show()\n    # print result\n    print(f\"Acc = {accuracy_score(y_test, y_pred)}\")\n    print(f\"F1 = {f1_score(y_test, y_pred, average='weighted')}\")\n```\n","data":{"description":"","title":"Doc2VecとOptunaを使ったSVMでのテキスト分類を作ってみた","slug":"doc2vec-svm-sentenceclassification","date":"2019-02-15T23:20:16.000Z","category":"Tech Blog","tags":["ML","NLP"]}},"__N_SSG":true}